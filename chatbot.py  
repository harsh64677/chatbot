import json
import random
import re
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
import nltk

nltk.download('wordnet')

# Tokenizer function to split sentences into words
def simple_tokenize(text):
    return re.findall(r"\b\w+\b", text.lower())

lemmatizer = WordNetLemmatizer()

# Load intents from JSON file
with open("intents.json") as file:
    data = json.load(file)

corpus = []
tags = []

# Preprocess data: tokenize, lemmatize, and build corpus and tags
for intent in data["intents"]:
    for pattern in intent["patterns"]:
        tokens = simple_tokenize(pattern)
        words = [lemmatizer.lemmatize(w) for w in tokens]
        corpus.append(" ".join(words))
        tags.append(intent["tag"])

# Convert text data to feature vectors
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)
y = tags

# Train Naive Bayes classifier
model = MultinomialNB()
model.fit(X, y)

# Function to get chatbot response
def chatbot_response(msg):
    tokens = simple_tokenize(msg)
    msg_processed = " ".join([lemmatizer.lemmatize(w) for w in tokens])
    X_test = vectorizer.transform([msg_processed])
    tag = model.predict(X_test)[0]
    for intent in data["intents"]:
        if intent["tag"] == tag:
            return random.choice(intent["responses"])

# Chat loop
print("Chatbot is ready! Type 'quit' to exit.")
while True:
    msg = input("You: ")
    if msg.lower() == "quit":
        print("Bot: Goodbye!")
        break
    print("Bot:", chatbot_response(msg))

